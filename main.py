import asyncio
import functools
import logging
import time
from pathlib import Path

import requests
from bs4 import BeautifulSoup, Tag

from utils import ask_ai_for_image_name

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
    # defaults={"details": ""},  # ä¸ºç¼ºå¤±çš„å­—æ®µæä¾›é»˜è®¤å€¼
)


async def main():
    # print((" Hello from image-downloader-ai-namer! ").center(100, "="))
    print(f"{' Hello from image-downloader-ai-namer! ':=^100}")

    await init(
        url="https://www.zcool.com.cn/work/ZNjIzODY0Njg=.html",
        selector="#newContent img",
        save_dir=r"E:\download-2024-5-8\é…å›¾\temp",
    )


def timing(precision=2, show_func_name=False, label=""):
    """
    è£…é¥°å™¨ï¼Œç”¨äºè®¡ç®—å‡½æ•°çš„æ‰§è¡Œæ—¶é—´ã€‚

    ## Features
    - åŒæ­¥å’Œå¼‚æ­¥å‡½æ•°å‡å¯ä½¿ç”¨ã€‚

    :param func: è¦è£…é¥°çš„å‡½æ•°
    :param precision: å°æ•°ç‚¹åç²¾åº¦
    :param show_func_name: æ˜¯å¦æ˜¾ç¤ºå‡½æ•°å
    :param label: è‡ªå®šä¹‰æ ‡ç­¾
    """

    def decorator(func):
        time_label = label or ((func.__name__ if show_func_name else "") + "è€—æ—¶: ")

        def print_time(start_time, end_time):
            print(f"{time_label}{end_time - start_time:.{precision}f} ç§’")

        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            result = func(*args, **kwargs)
            end_time = time.perf_counter()

            print_time(start_time, end_time)

            return result

        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            result = await func(*args, **kwargs)
            end_time = time.perf_counter()

            print_time(start_time, end_time)
            return result

        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

    return decorator


@timing(label="ä¸‹è½½è€—æ—¶ ")
async def init(url: str, selector: str, save_dir: str):
    if not url or not selector or not Path(save_dir).exists():
        logging.error(
            "âŒ url, imgs selector, and save_dir are required!"
            + " "
            + str(
                {
                    "url": url,
                    "selector": selector,
                    "save_dir": save_dir,
                    "save_dir_exists?": Path(save_dir).exists(),
                }
            )
        )
        return

    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36",
    }
    r = requests.get(url, headers=headers)
    html = r.text
    # print("HTML:", html)
    soup = BeautifulSoup(html, "html.parser")

    imgs = soup.css.select(selector)

    if len(imgs) == 0:
        logging.warning("No images found.")
        print(soup.getText(strip=True))

        return

    logging.info(f"found {len(imgs)} images.")

    tasks = [
        asyncio.create_task(download(img, index, save_dir))
        for index, img in enumerate(imgs)
    ]

    logging.info(f"â³ Executing {len(tasks)} tasks concurrently ğŸ¤¹...")

    await asyncio.gather(*tasks)

    logging.info("ğŸ¥³ Done.")


async def download(img: Tag, index: int, save_dir: str) -> None:
    img_url = img.get("data-src", img.get("src"))

    if not img_url:
        logging.warning(f"ğŸš« #{index + 1} no src found", img)
        return

    img_url = str(img_url)
    img_name = await ask_ai_for_image_name(str(img))
    logging.debug(f"{img_url, img_name}")

    full_path: Path = Path(save_dir) / img_name

    if not Path.exists(full_path):
        img_r = requests.get(img_url)
        with open(full_path, "wb") as f:
            f.write(img_r.content)
        logging.info(f"âœ… Downloaded #{index + 1} {img_name}")
    else:
        logging.warning("fâŒ {full_path} already exists")


if __name__ == "__main__":
    asyncio.run(main())
